---
services:
  # For simplicity, we use Confluent Platform Zookeeper here. The procedure is exactly the same for another zookeeper image
  zookeeper1:
    image: confluentinc/cp-zookeeper:${CP_VERSION}
    hostname: zookeeper1
    container_name: zookeeper1
    profiles: 
      - zookeeper
      - migration
    restart: always
    ports:
      - "21811:21811"
      - "31801:31801"
      - "21801:21801"
    volumes:
      - data-zookeeper-log-1:/var/lib/zookeeper/log
      - data-zookeeper-data-1:/var/lib/zookeeper/data
    environment:
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=*"
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_JMX_HOSTNAME: zookeeper1
      ZOOKEEPER_CLIENT_PORT: 21811
      ZOOKEEPER_JMX_PORT: 21801
      ZOOKEEPER_SERVERS: zookeeper1:2888:3888;zookeeper2:2888:3888;zookeeper3:2888:3888
 
  zookeeper2:
    image: confluentinc/cp-zookeeper:${CP_VERSION}
    hostname: zookeeper2
    container_name: zookeeper2
    profiles: 
      - zookeeper
      - migration
    restart: always
    ports:
      - "21812:21812"
      - "31802:31802"
      - "21802:21802"
    volumes:
      - data-zookeeper-log-2:/var/lib/zookeeper/log
      - data-zookeeper-data-2:/var/lib/zookeeper/data
    environment:
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=*"
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_JMX_HOSTNAME: zookeeper2
      ZOOKEEPER_CLIENT_PORT: 21812
      ZOOKEEPER_JMX_PORT: 21802
      ZOOKEEPER_SERVERS: zookeeper1:2888:3888;zookeeper2:2888:3888;zookeeper3:2888:3888

  zookeeper3:
    image: confluentinc/cp-zookeeper:${CP_VERSION}
    hostname: zookeeper3
    container_name: zookeeper3
    profiles: 
      - zookeeper
      - migration
    restart: always
    ports:
      - "21813:21813"
      - "31803:31803"
      - "21803:21803"
    volumes:
      - data-zookeeper-log-3:/var/lib/zookeeper/log
      - data-zookeeper-data-3:/var/lib/zookeeper/data
    environment:
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=*"
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_JMX_HOSTNAME: zookeeper3
      ZOOKEEPER_CLIENT_PORT: 21813
      ZOOKEEPER_JMX_PORT: 21803
      ZOOKEEPER_SERVERS: zookeeper1:2888:3888;zookeeper2:2888:3888;zookeeper3:2888:3888
 
  broker1:
    image: bitnami/kafka:${BITNAMI_KAFKA_VERSION}
    hostname: broker1
    container_name: broker1
    profiles: 
      - zookeeper
      - migration
      - kraft
    ports:
      - "29092:29092"
    volumes:
      - data-broker1:/bitnami/kafka
    environment:
      KAFKA_CFG_LISTENERS: BROKER://:9092,BROKER_HOST://0.0.0.0:29092
      KAFKA_CFG_ADVERTISED_LISTENERS: BROKER://broker1:9092,BROKER_HOST://localhost:29092
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,BROKER_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: BROKER
      # Use these lines only during Phase 1 (Zookeeper mode) and Phase 2 (Migration): DO NOT USE these lines in Phase 3!
      KAFKA_CFG_ZOOKEEPER_CONNECT: 'zookeeper1:21811,zookeeper2:21812,zookeeper3:21813'
      KAFKA_CFG_BROKER_ID: 1
      # Use these lines on in Phase 2 (Migration). DO NOT USE these lines in Phase 1 or Phase 3!
      #KAFKA_CFG_ZOOKEEPER_METADATA_MIGRATION_ENABLE: true
      # Use these lines on in Phase 2 (Migration) and Phase 3: Enable for migration and keep lines in final configuration
      #KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 101@controller1:9093,102@controller2:9093,103@controller3:9093
      #KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # Phase 3 (Migration finished): Enable these lines in the final configuration
      # Comment "KAFKA_CFG_BROKER_ID" (above), uncomment "KAFKA_CFG_NODE_ID" (below)
      #KAFKA_CFG_NODE_ID: 1
      #KAFKA_CFG_PROCESS_ROLES: broker

  broker2:
    image: bitnami/kafka:${BITNAMI_KAFKA_VERSION}
    hostname: broker2
    container_name: broker2
    profiles: 
      - zookeeper
      - migration
      - kraft
    ports:
      - "29093:29093"
    volumes:
      - data-broker2:/bitnami/kafka
    environment:
      KAFKA_CFG_LISTENERS: BROKER://:9092,BROKER_HOST://0.0.0.0:29093
      KAFKA_CFG_ADVERTISED_LISTENERS: BROKER://broker2:9092,BROKER_HOST://localhost:29093
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,BROKER_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: BROKER
      # Use these lines only during Phase 1 (Zookeeper mode) and Phase 2 (Migration): DO NOT USE these lines in Phase 3!
      KAFKA_CFG_ZOOKEEPER_CONNECT: 'zookeeper1:21811,zookeeper2:21812,zookeeper3:21813'
      KAFKA_CFG_BROKER_ID: 2
      # Use these lines on in Phase 2 (Migration). DO NOT USE these lines in Phase 1 or Phase 3!
      #KAFKA_CFG_ZOOKEEPER_METADATA_MIGRATION_ENABLE: true
      # Use these lines on in Phase 2 (Migration) and Phase 3: Enable for migration and keep lines in final configuration
      #KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 101@controller1:9093,102@controller2:9093,103@controller3:9093
      #KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # Phase 3 (Migration finished): Enable these lines in the final configuration
      # Comment "KAFKA_CFG_BROKER_ID" (above), uncomment "KAFKA_CFG_NODE_ID" (below)
      #KAFKA_CFG_NODE_ID: 2
      #KAFKA_CFG_PROCESS_ROLES: broker


  # KRaft Controllers
  controller1:
    image: bitnami/kafka:${BITNAMI_KAFKA_VERSION}
    hostname: controller1
    container_name: controller1
    profiles: 
      - migration
      - kraft
    volumes:
      - data-controller1:/bitnami/kafka
    environment:
      # Common
      KAFKA_CFG_PROCESS_ROLES: controller
      KAFKA_CFG_LISTENERS: CONTROLLER://controller1:9093
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT
      KAFKA_CFG_NODE_ID: 101
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 101@controller1:9093,102@controller2:9093,103@controller3:9093
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_KRAFT_CLUSTER_ID: ${KRAFT_CLUSTER_ID}
      KAFKA_CFG_KRAFT_REPLICATION_FACTOR: 3
      # Phase 2: Migration
      KAFKA_CFG_ZOOKEEPER_METADATA_MIGRATION_ENABLE: true
      KAFKA_CFG_ZOOKEEPER_CONNECT: 'zookeeper1:21811,zookeeper2:21812,zookeeper3:21813'
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: BROKER

  controller2:
    image: bitnami/kafka:${BITNAMI_KAFKA_VERSION}
    hostname: controller2
    container_name: controller2
    profiles: 
      - migration
      - kraft
    volumes:
      - data-controller2:/bitnami/kafka
    environment:
      # Common
      KAFKA_CFG_PROCESS_ROLES: controller
      KAFKA_CFG_LISTENERS: CONTROLLER://controller2:9093
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT
      KAFKA_CFG_NODE_ID: 102
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 101@controller1:9093,102@controller2:9093,103@controller3:9093
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_KRAFT_CLUSTER_ID: ${KRAFT_CLUSTER_ID}
      KAFKA_CFG_KRAFT_REPLICATION_FACTOR: 3
      # Phase 2: Migration
      KAFKA_CFG_ZOOKEEPER_METADATA_MIGRATION_ENABLE: true
      KAFKA_CFG_ZOOKEEPER_CONNECT: 'zookeeper1:21811,zookeeper2:21812,zookeeper3:21813'
      # Phase 2 (Migration) and Phase 3 (KRaft-only Mode)
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: BROKER

  controller3:
    image: bitnami/kafka:${BITNAMI_KAFKA_VERSION}
    hostname: controller3
    container_name: controller3
    profiles: 
      - migration
      - kraft
    volumes:
      - data-controller3:/bitnami/kafka
    environment:
      # Common
      KAFKA_CFG_PROCESS_ROLES: controller
      KAFKA_CFG_LISTENERS: CONTROLLER://controller3:9093
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT
      KAFKA_CFG_NODE_ID: 103
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 101@controller1:9093,102@controller2:9093,103@controller3:9093
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_KRAFT_CLUSTER_ID: ${KRAFT_CLUSTER_ID}
      KAFKA_CFG_KRAFT_REPLICATION_FACTOR: 3
      # Phase 2: Migration
      KAFKA_CFG_ZOOKEEPER_METADATA_MIGRATION_ENABLE: true
      KAFKA_CFG_ZOOKEEPER_CONNECT: 'zookeeper1:21811,zookeeper2:21812,zookeeper3:21813'
      # Phase 2 (Migration) and Phase 3 (KRaft-only Mode)
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: BROKER

  setup:
   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
   profiles: [elastic]
   user: "0"
   command: >
     bash -c '
       if [ x${ELASTIC_PASSWORD} == x ]; then
         echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
         exit 1;
       elif [ x${KIBANA_PASSWORD} == x ]; then
         echo "Set the KIBANA_PASSWORD environment variable in the .env file";
         exit 1;
       fi;
       echo "Waiting for Elasticsearch availability";
       until curl -s http://es01:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
       echo "Setting kibana_system password";
       until curl -s -X POST -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" http://es01:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
       echo "All done!";
     '

  es01:
   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
   hostname: es01
   profiles: [elastic]
   labels:
     co.elastic.logs/module: elasticsearch
   volumes:
     - esdata01:/usr/share/elasticsearch/data
   ports:
     - ${ES_PORT}:9200
   environment:
     - node.name=es01
     - cluster.name=${CLUSTER_NAME}
     - discovery.type=single-node
     - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
     - bootstrap.memory_lock=true
     - xpack.security.enabled=true
     - xpack.security.http.ssl.enabled=false
     - xpack.security.transport.ssl.enabled=false
     - xpack.license.self_generated.type=${LICENSE}
   mem_limit: ${ES_MEM_LIMIT}
   ulimits:
     memlock:
       soft: -1
       hard: -1
   healthcheck:
     test:
       [
         "CMD-SHELL",
         "curl -s http://localhost:9200 | grep -q 'missing authentication credentials'",
       ]
     interval: 10s
     timeout: 10s
     retries: 120

  kibana:
   depends_on:
     es01:
       condition: service_healthy
   image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
   hostname: kibana
   profiles: [elastic]
   labels:
     co.elastic.logs/module: kibana
   volumes:
     - kibanadata:/usr/share/kibana/data
     - ./config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
   ports:
     - ${KIBANA_PORT}:5601
   environment:
     - SERVERNAME=kibana
     - ELASTICSEARCH_HOSTS=http://es01:9200
     - ELASTICSEARCH_USERNAME=kibana_system
     - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
     - XPACK_SECURITY_ENCRYPTIONKEY=${ENCRYPTION_KEY}
     - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ENCRYPTION_KEY}
     - XPACK_REPORTING_ENCRYPTIONKEY=${ENCRYPTION_KEY}
     - XPACK_REPORTING_KIBANASERVER_HOSTNAME=localhost
     - SERVER_SSL_ENABLED=false
   mem_limit: ${KB_MEM_LIMIT}
   healthcheck:
     test:
       [
         "CMD-SHELL",
         "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
       ]
     interval: 10s
     timeout: 10s
     retries: 120

  # Docker container for running the configured fleet agent. The agent will capture docker logs
  fleet-server:
    depends_on:
      kibana:
        condition: service_healthy
      es01:
        condition: service_healthy
    profiles: [elastic]
    image: docker.elastic.co/beats/elastic-agent:${STACK_VERSION}
    volumes:
      - "fleetserverdata:/usr/share/elastic-agent"
      - "/var/lib/docker/containers:/var/lib/docker/containers:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro"
      - "/proc:/hostfs/proc:ro"
      - "/:/hostfs:ro"
    ports:
      - ${FLEET_PORT}:8220
    user: root
    environment:
      - FLEET_ENROLL=1
      - FLEET_INSECURE=true
      - FLEET_SERVER_ELASTICSEARCH_HOST=http://es01:9200
      - FLEET_SERVER_ELASTICSEARCH_INSECURE=true
      - FLEET_SERVER_ENABLE=1
      - FLEET_SERVER_INSECURE_HTTP=true
      - FLEET_SERVER_POLICY_ID=fleet-server-policy
      - FLEET_URL=http://fleet-server:8220
      - KIBANA_FLEET_SETUP=1
      - KIBANA_FLEET_USERNAME=elastic
      - KIBANA_FLEET_PASSWORD=${ELASTIC_PASSWORD}
      - KIBANA_HOST=http://kibana:5601

volumes:
  data-zookeeper-log-1:
    driver: local
  data-zookeeper-data-1:
    driver: local
  data-zookeeper-log-2:
    driver: local
  data-zookeeper-data-2:
    driver: local
  data-zookeeper-log-3:
    driver: local
  data-zookeeper-data-3:
    driver: local
  data-broker1:
    driver: local
  data-broker2:
    driver: local
  data-controller1:
    driver: local
  data-controller2:
    driver: local
  data-controller3:
    driver: local
  esdata01:
    driver: local
  kibanadata:
    driver: local
  fleetserverdata:
    driver: local
